{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9liCMfYXjv7p"
   },
   "source": [
    "# 3.1 Cleaning dirty data\n",
    "\n",
    "Before diving into data analysis, it is crucial to ensure that your dataset is clean and well-prepared. Data cleaning involves identifying and rectifying issues, such as missing values, incorrect data types, and typos, to ensure the data is accurate and usable. In this lesson, we will explore various data cleaning techniques using Python Pandas, which will help us transform messy data into a structured and reliable format.\n",
    "\n",
    "## Why data cleaning matters\n",
    "\n",
    "Data cleaning is a critical step in the data analysis process for several reasons:\n",
    "\n",
    "- Accurate analysis: Clean data ensures the reliability of your analysis, leading to accurate results and insights.\n",
    "- Improved data quality: High-quality data leads to better decision-making and more robust conclusions.\n",
    "- Enhanced efficiency: Clean data reduces the risk of errors and streamlines the analysis process.\n",
    "\n",
    "A big advantage of cleaning data in Python is that you can run the same code over and over. This is especially useful when you will continually update a dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PnLPLQ-lFdD"
   },
   "source": [
    "## Data integrity checks\n",
    "\n",
    "First, as always, start with checking the integrity of your dataset. This means checking:\n",
    "\n",
    "- the number of columns and rows (shape)\n",
    "- the numerical columns - looking for outliers or other weird issues (describe)\n",
    "- the number of blanks (isnull)\n",
    "- data types (dtypes)\n",
    "- misspellings and other typos\n",
    "\n",
    "And then fixing any issues you find!\n",
    "\n",
    "###Import data\n",
    "\n",
    "For this lesson we'll work with a database of movies and shows on Netflix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1694282853680,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "cF0ZiXKfoRYH",
    "outputId": "e9980c58-e7f1-479e-9357-acdcc9573ef7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data from a CSV file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dnmalan/advanced-data-journalism-23/main/data/netflix_titles.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q0eEYUwo13l"
   },
   "source": [
    "Right off the bat we can see that there are a few issues with this dataset:\n",
    "\n",
    "- missing values (NAN = Not A Number, which is how pandas denotes blanks or nulls)\n",
    "- columns with lots of values separated by commas (listed_in)\n",
    "- columns with words and numbers (date_added)\n",
    "- the duration has mixed units (minutes/seasons)\n",
    "\n",
    "### Check record count and check for blanks\n",
    "\n",
    "Let's run a few more checks to get to know our data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1694280752991,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "Ms8F176NpULO",
    "outputId": "555959ff-e0a2-4fab-dfce-053c5e32d3e2"
   },
   "outputs": [],
   "source": [
    "#check how many rows and columns\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1694280754906,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "1f21OjHNpbxc",
    "outputId": "1d43dbe5-5af9-47cf-d54e-912e239ca33c"
   },
   "outputs": [],
   "source": [
    "#how many blanks?\n",
    "\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1694280881995,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "pNtBYh2TAGYR",
    "outputId": "d35e3b11-f655-44dd-a226-6f8006925495"
   },
   "outputs": [],
   "source": [
    "# count how many nulls by adding sum()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1694280913680,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "s1XkdbSsAqvN",
    "outputId": "52fbc98e-38a7-4162-b91e-4b84535adb2b"
   },
   "outputs": [],
   "source": [
    "#what percentage of each column is null?\n",
    "\n",
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmBJcitaA5MK"
   },
   "source": [
    "We can see that some columns have very few NaNs, so we won't worry too much about them. But some of the columns, like director, cast, and country, have a higher percentage. These might be a problem.\n",
    "\n",
    "You can deal with missing values in a few ways. If there are a larger number of blanks, you likely can't use the column or would have to fill in the missing data. If there are a smaller number of blanks you can likely ignore them. In some cases you might use the column but put a disclaimer on your analysis.\n",
    "\n",
    "For now, let's get rid of the NaNs by replacing them with true blanks (\"\") using the **.fillna()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baT_hvLDCvzD"
   },
   "outputs": [],
   "source": [
    "# names of the columns\n",
    "columns = ['director', 'cast', 'country', 'rating', 'date_added']\n",
    "\n",
    "# looping through the columns to fill the entries with NaN values with \"\"\n",
    "for column in columns:\n",
    "    df[column] = df[column].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo2rCeoqBslv"
   },
   "source": [
    "### Check data types\n",
    "\n",
    "Now let's check the data types in each column. This affects how we will write our code later, so it's very important. You might need to changes data types depending on what you want to do. For example, numbers are sometimes stored as text (or objects), and mathematical functions won't work unless you change the column type to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1694281254869,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "EbzQOTZuCAKc",
    "outputId": "77810b6b-e469-4f68-8d89-a74bf67064a4"
   },
   "outputs": [],
   "source": [
    "# check column data types\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD7UGug3CHzv"
   },
   "source": [
    "Here we see most of the columns are \"object\" (text aka string), with the exception of year, which is an \"int64\" (integer). This should be fine for our analysis. If you need to change datatypes, you can use functions such as **to_numeric()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEDpuRUvJcP3"
   },
   "source": [
    "### Getting rid of trailing or leading spaces\n",
    "\n",
    "Text data sometimes has spaces in front of or after the text. You might not be able to see it, but to the computer, it is there, and it means your data is dirty. Values of \"hello\" and \"hello \" are two different values, even though we want them to be the same.\n",
    "\n",
    "With text columns, it's a good idea to get rid of trailing and leading spaces before doing any further cleaning. It can save you some trouble!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymNRLQmzD0aa"
   },
   "source": [
    "### Checking for typos, misspellings, and general dirty data\n",
    "\n",
    "You should check text columns for misspellings and typos that could come into play when you're grouping. You can do this by running a **group by** as we did in Lesson 2, or you can also use another function called **unique**, which returns every unique value in a column.\n",
    "\n",
    "In this dataset, we know that columns like director and cast will have many different unique values, so it doesn't make sense to check them. But let's check the rating to see what values exist in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1694281871462,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "qpFxJ-37EVfm",
    "outputId": "609ffaba-c73a-4448-d250-5e4817766100"
   },
   "outputs": [],
   "source": [
    "#check unique values in rating column\n",
    "\n",
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XwbLhIgEdI8"
   },
   "source": [
    "Most of these look good, but there are some values that appear to be durations (84 mins, 66 mins). We won't fix them here today, but you can move these to the duration column where they belong.\n",
    "\n",
    "There are also two values that mean the same thing (NR or \"not rated\" and UR or \"unrated\"). We can easily fix these by changing all the URs to NRs (the correct designation).\n",
    "\n",
    "We'll look at two different ways to do this, since cleaning up data this way is very common!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1694282172928,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "HT333bYTFYyZ",
    "outputId": "e1bd58f3-240c-4eee-c185-8cd25bbeb091"
   },
   "outputs": [],
   "source": [
    "# Method 1: Using a for loop.\n",
    "# This loops through the rows, and each time it sees a UR, it replaces it with an NR\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['rating'].iloc[i] == \"UR\":\n",
    "       df['rating'].iloc[i] = \"NR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocpmJqJqFotL"
   },
   "outputs": [],
   "source": [
    "# Method 2: Using WHERE from the numpy library\n",
    "# This uses a filter to search for the bad values and replaces them with the new ones.\n",
    "\n",
    "df['rating'] = np.where((df['rating'] == 'UR'), 'NR', df['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1694283046000,
     "user": {
      "displayName": "Denise Malan",
      "userId": "13140940367276605614"
     },
     "user_tz": 420
    },
    "id": "ZY18hj6gIzI-",
    "outputId": "e0cf007c-da72-448c-f850-bfc401b6670f"
   },
   "outputs": [],
   "source": [
    "# check the results\n",
    "\n",
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byn49eC0J-BE"
   },
   "source": [
    "That's as far as we'll go with data cleaning today. Check out [this blog](https://www.einblick.ai/blog/data-cleaning-with-python/) for some other great functions and tips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C1_C40wKIV1"
   },
   "source": [
    "## Automation through APIs\n",
    "\n",
    "APIs, or Application Programming Interfaces, are a set of rules and protocols that allow different software applications to communicate with each other. They define the methods and data formats that applications can use to request and exchange information. APIs are commonly used to access web services, retrieve data from external sources, or perform specific actions programmatically. In this lesson, we will explore what APIs are and how to use Python to connect to a sample API.\n",
    "\n",
    "### Connecting to a Sample API: OpenWeatherMap\n",
    "\n",
    "[OpenWeatherMap](https://openweathermap.org/) is a popular weather data provider that offers an API to access weather information for various locations around the world. We will use their free API to retrieve weather data for a specific city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your API key\n",
    "api_key = '2a0e9b7229dd5307178422c8f6c88b9a'\n",
    "\n",
    "# Define the API endpoint URL\n",
    "api_url = f'https://api.openweathermap.org/data/2.5/onecall?lat=39.90&lon=116.40&exclude=hourly,daily&units=metric&appid={api_key}'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Access the weather information in the 'current' object\n",
    "    current_weather = data['current']\n",
    "    \n",
    "    # Extract relevant weather information\n",
    "    temperature = current_weather['temp']\n",
    "    humidity = current_weather['humidity']\n",
    "    weather_description = current_weather['weather'][0]['description']\n",
    "    \n",
    "    # Display the weather information\n",
    "    print(f'Temperature: {temperature}°C')\n",
    "    print(f'Humidity: {humidity}%')\n",
    "    print(f'Weather Description: {weather_description}')\n",
    "else:\n",
    "    print('Failed to retrieve weather data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCnFl9COMz7t"
   },
   "source": [
    "### examples of some other API urls for open weather\n",
    "\n",
    "get data by latitude/longitude\n",
    "https://api.openweathermap.org/data/3.0/onecall?lat={lat}&lon={lon}&appid={APIkey}\n",
    "\n",
    "request historical data\n",
    "https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={time}&appid={APIkey}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying World Bank data API for GDP data\n",
    "\n",
    "Information about the API at this link: https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the base URL for the World Bank Open Data API\n",
    "base_url = \"https://api.worldbank.org/v2/country/CN/indicator/NY.GDP.MKTP.CD\"\n",
    "\n",
    "# Define the parameters for the query\n",
    "params = {\n",
    "    \"format\": \"json\",\n",
    "    \"per_page\": 10000,  # Set a high number to retrieve all available data points\n",
    "}\n",
    "\n",
    "# Send a GET request to the World Bank API\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract and print the GDP data for China over time\n",
    "    for item in data[1]:\n",
    "        year = item['date']\n",
    "        gdp = item['value']\n",
    "        print(f\"Year: {year}, GDP: {gdp}\")\n",
    "else:\n",
    "    print('Failed to retrieve GDP data for China.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the base URL for the World Bank Open Data API\n",
    "base_url = \"https://api.worldbank.org/v2/country/CN/indicator/NY.GDP.MKTP.CD\"\n",
    "\n",
    "# Define the parameters for the query\n",
    "params = {\n",
    "    \"format\": \"json\",\n",
    "    \"per_page\": 10000,  # Set a high number to retrieve all available data points\n",
    "}\n",
    "\n",
    "# Send a GET request to the World Bank API\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()[1]\n",
    "    \n",
    "    # Extract and format the data into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df['date'] = pd.to_datetime(df['date'])  # Convert the date column to datetime\n",
    "    \n",
    "    # Create a line chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['date'], df['value'], marker='o', linestyle='-')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('GDP (Current US$)')\n",
    "    plt.title('GDP of China Over Time')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Failed to retrieve GDP data for China.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMBXHrEXrucwaqWLWTqgSxP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
